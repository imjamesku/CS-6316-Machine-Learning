{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GcnpyYtrB2sg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "# load necessary modules\n",
    "%pylab inline\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "# import white-box training modules\n",
    "from mnist_nets.train_mnist_nets import main as build_mnist_nets\n",
    "from mnist_nets.postprocess_mnist_nets import main as postprocess_mnist_nets\n",
    "\n",
    "# import metamodel training modules\n",
    "from mnist_metamodel.mnist_metamodel import config as config_metamodel\n",
    "from mnist_metamodel.mnist_metamodel import main as train_metamodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ir7wGlP4BqgV"
   },
   "source": [
    "# Towards Reverse-Engineering Black-Box Neural Networks, ICLR'18\n",
    "## Authors: Seong Joon Oh, Max Augustin, Bernt Schiele, Mario Fritz (Code available at https://github.com/coallaoh/WhitenBlackBox)\n",
    "\n",
    "### presented by Team Taiwan James Ku, Hannah Chen, Li-Pang Huang\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dCBfro65U92T"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.5/dist-packages (1.3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from torch==1.3.1) (1.15.4)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: torchvision==0.4.2 in /usr/local/lib/python3.5/dist-packages (0.4.2)\n",
      "Requirement already satisfied: torch==1.3.1 in /usr/local/lib/python3.5/dist-packages (from torchvision==0.4.2) (1.3.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (from torchvision==0.4.2) (1.15.4)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from torchvision==0.4.2) (1.10.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.5/dist-packages (from torchvision==0.4.2) (6.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.1.1, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install package\n",
    "!pip3 install torch==1.3.1\n",
    "!pip3 install torchvision==0.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the data?\n",
    "In this paper, they use a diverse set of white-box models with different model attributes.\n",
    "\n",
    "## How to crack the black-box-model?\n",
    "### 1. kennen-o\n",
    "kennen-o first selects a fixed set of queries (images) from a dataset. Both during training\n",
    "and testing, always these queries are submitted.\n",
    "kennen-o learns a classifier $m_\\theta$ to map from\n",
    "the outputs from $f$, $[f(x_\n",
    "i)]_{i=1···n}$ (n×10 dim for MNIST), to\n",
    "the simultaneous prediction of the 12 attributes in $f$\n",
    "### 2. kennen-i\n",
    "kennen-i crafts a single query input $\\widetilde{x}$ over the meta-training models that is trained to repurpose a digit classifier f into a model attribute classifier for a single attribute a. The crafted input drives the classifier to leak internal information via digit prediction. The learned input is submitted to the test black-box model g, and the attribute is predicted by reading off its digit prediction g(˜x). For example, kennen-i for max-pooling layer prediction crafts an input $x$ that is predicted as “1” for\n",
    "generic MNIST digit classifiers with max-pooling layers and “0” for ones without.\n",
    "\n",
    "### 3. kennen-io\n",
    "Kennen-io overcomes the drawbacks of kennen-i that it can only predict one attribute at a time and that the number of predictable classes by attaching an additional interpretation module on top of the output. Our final method kennen-io combines kennen-i and kennen-o approaches: both\n",
    "input generator and output interpreters are used. Being able to reason over multiple query outputs via MLP layers, kennen-io supports the optimisation of multiple query inputs as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 409
    },
    "colab_type": "code",
    "id": "Ca2d8OpWSvmJ",
    "outputId": "456132c4-3c84-4165-bed3-4757ac1d4d7d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Creating white-box models\n",
    "# The white-box models are trained by MNIST dataset\n",
    "\n",
    "if False:\n",
    "    build_mnist_nets()\n",
    "    postprocess_mnist_nets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XoK0yksYS75i"
   },
   "source": [
    "Train metamodels, the metamodels will predict the architecture, hyperparameters, and data set of the black-box-models.\n",
    "\n",
    "|              |  Code |    Attribute   |                   Values                   |\n",
    "|:------------:|:-----:|:--------------:|:------------------------------------------:|\n",
    "| Architecture |  act  |   Activation   |           ReLU, PReLU, ELU, Tanh           |\n",
    "|              |  drop |     Dropout    |                   Yes, No                  |\n",
    "|              |  pool |   Max pooling  |                   Yes, No                  |\n",
    "|              |   ks  | Conv ker. size |                    3, 5                    |\n",
    "|              | #conv |  #Conv layers  |                   2, 3, 4                  |\n",
    "|              |  #FC  |   #FC layers   |                   2, 3, 4                  |\n",
    "|              |  #par |   #Parameters  |           $$2^{14}, ..., 2^{21}$$          |\n",
    "|              |  ens  |    Ensemble    |                   Yes, No                  |\n",
    "|--------------|-------|----------------|--------------------------------------------|\n",
    "| optimisation |  alg  |    Algorithm   |             SGD, ADAM, RMSprop             |\n",
    "|              |   bs  |   Batch size   |                64, 128, 256                |\n",
    "|--------------|-------|----------------|--------------------------------------------|\n",
    "|     Data     | split |   Data split   | $$All_{0}, Half_{0/1}, Quarter_{0/1/2/3}$$ |\n",
    "|              |  size |    Data size   |             All, Half, Quarter             |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "id": "Bq-W7R0JTEGT",
    "outputId": "bfaac85e-8d6b-41f6-fb13-4988e089c266"
   },
   "outputs": [],
   "source": [
    "# example_no = 1 indicates kennen-o method\n",
    "example_no = 1\n",
    "\n",
    "if example_no == 1:\n",
    "    # kennen-o approach with 5000 training models and 100 queries with top-5 ranking outputs\n",
    "    # under the Random (R) split.\n",
    "    METHOD = 'm'  # Refers to kennen-o\n",
    "    N_TRAIN = 5000  # Can be chosen in range [100,5000]\n",
    "    N_EPOCH = 200  # Default number of epochs used in the paper\n",
    "    N_QUERY = 100  # Can be chosen in range [1,1000]\n",
    "    OUTPUT = 'ranking-5'  # ranking-k refers to top-k ranking output\n",
    "    SPLIT = 'rand'\n",
    "    SPLIT_TR = [1]  # Train on split 1\n",
    "    SPLIT_TE = [0]  # Test on split 0\n",
    "    GPU = None  # No GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vEcpsVO6TOOw"
   },
   "source": [
    "```\n",
    "Train Epoch: 200 [0/5000 (0%)]  Loss: 3.461459  Avg acc: 89.3%\n",
    "Train Epoch: 200 [1100/5000 (22%)]      Loss: 2.787968  Avg acc: 92.0%\n",
    "Train Epoch: 200 [2200/5000 (44%)]      Loss: 3.086313  Avg acc: 88.8%\n",
    "Train Epoch: 200 [3300/5000 (66%)]      Loss: 3.748855  Avg acc: 83.9%\n",
    "Train Epoch: 200 [4400/5000 (88%)]      Loss: 3.476222  Avg acc: 84.0%\n",
    "Testing..\n",
    "                 /etc/ens : 51.9% (RC 50.0%)\n",
    "           /etc/data_size : 73.6% (RC 33.3%)\n",
    "             /etc/n_param : 43.4% (RC 14.3%)\n",
    "                     _____\n",
    "                 /net/act : 67.2% (RC 25.0%)\n",
    "                /net/drop : 95.5% (RC 50.0%)\n",
    "                /net/n_fc : 72.6% (RC 33.3%)\n",
    "              /net/n_conv : 63.0% (RC 33.3%)\n",
    "                /net/pool : 96.9% (RC 50.0%)\n",
    "                  /net/ks : 79.1% (RC 50.0%)\n",
    "                     _____\n",
    "          /opt/batch_size : 52.0% (RC 33.3%)\n",
    "           /opt/optimiser : 66.5% (RC 33.3%)\n",
    "                     _____\n",
    "             /data/subset : 85.7% (RC 14.3%)\n",
    "                     _____\n",
    "                     _____\n",
    "Test loss: 7.500472, avgacc: 67.37%\n",
    "[51.9    73.6    43.4    67.2    95.5    72.6    63.0    96.9    79.1    52.0   66.5     85.7   ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GqFljAjsaN3K"
   },
   "outputs": [],
   "source": [
    "# example_no = 2 indicates kennen-i method\n",
    "example_no = 2\n",
    "\n",
    "if example_no == 2:\n",
    "    # kennen-i approach with 3000 training models\n",
    "    # under the Extrapolation (E) split, with splitting attribute {#conv}.\n",
    "    METHOD = 'i'  # Refers to kennen-i\n",
    "    N_TRAIN = 3000\n",
    "    N_EPOCH = 200\n",
    "    N_QUERY = 1  # kennen-i always submits a single query\n",
    "    OUTPUT = 'argmax'  # kennen-i only requires argmax output\n",
    "    SPLIT = 'ex^net/n_conv'  # Extrapolation (E) split, the format is 'ex^{attr1}^{attr2}'\n",
    "    # where attr1 and attr2 are the splitting attributes. For the full list of attributes,\n",
    "    # see the bottom of this script.\n",
    "    SPLIT_TR = [0, 1]  # Train on splits 0 and 1 (corresponds to #conv=2 or 3 - see bottom of page)\n",
    "    SPLIT_TE = [2]  # Test on split 2 (corresponds to #conv=4)\n",
    "    GPU = 1  # GPU ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_3nzoaMFTqRa"
   },
   "source": [
    "Result 1\n",
    "```\n",
    "Train Epoch: 200 [0/3000 (0%)]  Loss: 47.693123 Avg acc: 25.5%\n",
    "Train Epoch: 200 [810/3000 (27%)]       Loss: 82.349965 Avg acc: 28.4%\n",
    "Train Epoch: 200 [1620/3000 (54%)]      Loss: 42.829766 Avg acc: 37.1%\n",
    "Train Epoch: 200 [2430/3000 (81%)]      Loss: 29.483426 Avg acc: 34.9%\n",
    "Testing..\n",
    "Test batch: [950/1000 (95%)]\n",
    "                 /etc/ens : 43.2% (RC 100.0%)\n",
    "             /etc/n_param : 20.2% (RC 33.3%)\n",
    "           /etc/data_size : 36.5% (RC 33.3%)\n",
    "                     _____\n",
    "             /data/subset : 15.9% (RC 14.3%)\n",
    "                     _____\n",
    "           /opt/optimiser : 32.4% (RC 33.3%)\n",
    "          /opt/batch_size : 33.0% (RC 33.3%)\n",
    "                     _____\n",
    "                 /net/act : 27.1% (RC 25.0%)\n",
    "                  /net/ks : 53.1% (RC 50.0%)\n",
    "                /net/pool : 57.1% (RC 50.0%)\n",
    "                /net/drop : 53.6% (RC 50.0%)\n",
    "                /net/n_fc : 35.1% (RC 33.3%)\n",
    "              /net/n_conv : 29.0% (RC 100.0%)\n",
    "                     _____\n",
    "                     _____\n",
    "Test loss: 49.714847, avgacc: 32.86%\n",
    "[43.2    20.2    36.5    15.9    32.4    33.0    27.1    53.1    57.1    53.6   35.1     29.0   ]\n",
    "```\n",
    "\n",
    "Result 2\n",
    "```\n",
    "Train Epoch: 200 [0/3000 (0%)]\tLoss: 36.355844\tAvg acc: 44.5%\n",
    "Train Epoch: 200 [810/3000 (27%)]\tLoss: 56.740074\tAvg acc: 40.7%\n",
    "Train Epoch: 200 [1630/3000 (54%)]\tLoss: 949.217090\tAvg acc: 44.3%\n",
    "Train Epoch: 200 [2430/3000 (81%)]\tLoss: 28.991809\tAvg acc: 30.4%\n",
    "Testing..\n",
    "Test batch: [950/1000 (95%)]\n",
    "              /net/n_conv : 32.8% (RC 100.0%)\n",
    "                /net/pool : 55.2% (RC 50.0%)\n",
    "                /net/drop : 56.7% (RC 50.0%)\n",
    "                 /net/act : 25.5% (RC 25.0%)\n",
    "                  /net/ks : 55.7% (RC 50.0%)\n",
    "                /net/n_fc : 38.4% (RC 33.3%)\n",
    "                     _____\n",
    "           /etc/data_size : 37.5% (RC 33.3%)\n",
    "             /etc/n_param : 24.7% (RC 33.3%)\n",
    "                 /etc/ens : 50.8% (RC 100.0%)\n",
    "                     _____\n",
    "          /opt/batch_size : 33.2% (RC 33.3%)\n",
    "           /opt/optimiser : 33.4% (RC 33.3%)\n",
    "                     _____\n",
    "             /data/subset : 16.1% (RC 14.3%)\n",
    "                     _____\n",
    "                     _____\n",
    "Test loss: 48.639595, avgacc: 41.78%\n",
    "[32.8\t 55.2\t 56.7\t 25.5\t 55.7\t 38.4\t 37.5\t 24.7\t 50.8\t 33.2\t 33.4\t 16.1\t]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "id": "62_b85tPCMvW",
    "outputId": "bb52a040-71af-47d3-ee0c-84d645c07c6c"
   },
   "outputs": [],
   "source": [
    "# example_no = 3 indicates kennen-io method\n",
    "example_no = 3\n",
    "\n",
    "if example_no == 3:\n",
    "    # kennen-io approach with 100 training models and 100 queries with score outputs\n",
    "    # under the Extrapolation (E) split, with splitting attribute {#conv,#fc}.\n",
    "    METHOD = 'mi'  # Refers to kennen-io\n",
    "    N_TRAIN = 100\n",
    "    N_EPOCH = 400  # Default number of epochs for kennen-io\n",
    "    N_QUERY = 100\n",
    "    OUTPUT = 'score'\n",
    "    SPLIT = 'ex^net/n_conv^net/n_fc'  # Possible to set multiple splitting attributes separated via '^'\n",
    "    SPLIT_TR = [0, 1]  # Train on #conv=#fc=2 or 3\n",
    "    SPLIT_TE = [2]  # Test on #conf=#fc=4\n",
    "    GPU = 0  # GPU ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BihhGsQNeXfA"
   },
   "source": [
    "Result 1\n",
    "```\n",
    "Train Epoch: 400 [0/100 (0%)]   Loss: 3.739715  Avg acc: 91.1%\n",
    "Testing..\n",
    "Test batch: [870/1000 (87%)]\n",
    "           /etc/data_size : 42.5% (RC 33.3%)\n",
    "                 /etc/ens : 50.0% (RC 50.0%)\n",
    "             /etc/n_param : 10.0% (RC 20.0%)\n",
    "                     _____\n",
    "           /opt/optimiser : 50.1% (RC 33.3%)\n",
    "          /opt/batch_size : 39.2% (RC 33.3%)\n",
    "                     _____\n",
    "             /data/subset : 32.3% (RC 14.3%)\n",
    "                     _____\n",
    "                  /net/ks : 51.5% (RC 50.0%)\n",
    "                /net/n_fc : 0.0% (RC 100.0%)\n",
    "              /net/n_conv : 0.2% (RC 100.0%)\n",
    "                 /net/act : 49.1% (RC 25.0%)\n",
    "                /net/pool : 62.6% (RC 50.0%)\n",
    "                /net/drop : 66.8% (RC 50.0%)\n",
    "                     _____\n",
    "                     _____\n",
    "Test loss: 37.318427, avgacc: 36.78%\n",
    "[42.5    50.0    10.0    50.1    39.2    32.3    51.5    0.0     0.2     49.1   62.6     66.8   ]\n",
    "```\n",
    "\n",
    "Result 2\n",
    "```\n",
    "Train Epoch: 400 [0/100 (0%)]   Loss: 3.576666  Avg acc: 95.3%\n",
    "Testing..\n",
    "Test batch: [860/1000 (86%)]\n",
    "                /net/drop : 70.3% (RC 50.0%)\n",
    "              /net/n_conv : 0.0% (RC 100.0%)\n",
    "                  /net/ks : 52.6% (RC 50.0%)\n",
    "                /net/n_fc : 0.0% (RC 100.0%)\n",
    "                /net/pool : 62.9% (RC 50.0%)\n",
    "                 /net/act : 45.9% (RC 25.0%)\n",
    "                     _____\n",
    "          /opt/batch_size : 34.9% (RC 33.3%)\n",
    "           /opt/optimiser : 50.1% (RC 33.3%)\n",
    "                     _____\n",
    "             /etc/n_param : 12.5% (RC 20.0%)\n",
    "           /etc/data_size : 39.7% (RC 33.3%)\n",
    "                 /etc/ens : 50.0% (RC 50.0%)\n",
    "                     _____\n",
    "             /data/subset : 38.1% (RC 14.3%)\n",
    "                     _____\n",
    "                     _____\n",
    "Test loss: 37.420744, avgacc: 38.66%\n",
    "[70.3    0.0     52.6    0.0     62.9    45.9    34.9    50.1    12.5    39.7    50.0    38.1   ]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 392
    },
    "colab_type": "code",
    "id": "IYZil0DwESQq",
    "outputId": "7c50f5c7-c745-40f4-cb13-a2697105c955"
   },
   "outputs": [],
   "source": [
    "co = config_metamodel(\n",
    "    control=dict(\n",
    "        method=METHOD,\n",
    "        data=dict(\n",
    "            name='dnet10000',\n",
    "            subset=N_TRAIN,\n",
    "            eval=1000,\n",
    "        ),\n",
    "        seed=0,\n",
    "        i=dict(\n",
    "            init='randval',\n",
    "            clip=[0, 1],\n",
    "            noise='U1',\n",
    "            opt=dict(\n",
    "                optimiser='SGD',\n",
    "                lr=0.1,\n",
    "                weight_decay=0.0,\n",
    "                batch_size=10,\n",
    "            ),\n",
    "        ),\n",
    "        m=dict(\n",
    "            name='mlp_3_1000',\n",
    "            opt=dict(\n",
    "                optimiser='SGD',\n",
    "                lr=1e-4,\n",
    "                weight_decay=0.01,\n",
    "                batch_size=100,\n",
    "            ),\n",
    "        ),\n",
    "        opt=dict(\n",
    "            epochs=N_EPOCH,\n",
    "            sequence=['m', 200, 50, 50],\n",
    "            # sequence=['m', 1, 1, 1],\n",
    "        ),\n",
    "        setup=dict(\n",
    "            nquery=N_QUERY,\n",
    "            qseed=0,\n",
    "            target='all',\n",
    "            outrep=OUTPUT,\n",
    "            split=SPLIT,\n",
    "            splitidtr=SPLIT_TR,\n",
    "            splitidte=SPLIT_TE,\n",
    "        ),\n",
    "    ),\n",
    "    conf=dict(\n",
    "        exp_phase='mnist_metamodel',\n",
    "        balanced_eval=True,\n",
    "        test_batch_size=10,\n",
    "        test_epoch=1,\n",
    "        save=False,\n",
    "        overridecache=True,\n",
    "        mode='train',\n",
    "        gpu=GPU,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3a204GaZeCW"
   },
   "source": [
    "## Discussion of results\n",
    "\n",
    "### 1. kennen-o\n",
    "The average accuracy is 67.37% which is similar to the accuracy in the paper. In our implementation, the output we used is ranking-5; in the paper, the autohr used ranking-10.\n",
    "\n",
    "|         |  act  |  drop  |  pool  |  ks    |  #conv |  #fc   |  #par  |  ens   |  alg   |  bs  |  size  |  split |  avg|\n",
    "|:------|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|\n",
    "| Impelment result |  51.9  |  73.6  |  43.4  |  67.2  |  95.5  |  72.6  |  63.0  |  96.9  |  79.1  |  52.0  |  66.5  |  85.7  | 67.37  |\n",
    "| Paper |  63.7  |  93.8  |  90.8  |  80.0  |  63.0  |  73.7  |  44.1  |  62.4  |  65.3  |  47.0  |  66.2  |  86.6  | 69.7  |\n",
    "\n",
    "### 2. kennen-i\n",
    "The average accuracy are 32.86% and 41.78 which are both lower than the accuracy in the paper. In kennen-i, the query method is single query, so the result is not stable.\n",
    "\n",
    "|         |  act  |  drop  |  pool  |  ks    |  #conv |  #fc   |  #par  |  ens   |  alg   |  bs  |  size  |  split |  avg|\n",
    "|:------|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|\n",
    "| Impelment result 1 |  43.2  |  20.2  |  36.5  |  15.9  |  32.4  |  33.0  |  27.1  |  53.1  |  57.1  |  53.6  |  35.1  |  29.0  | 32.86 |\n",
    "| Impelment result 2 |  32.8  |  55.2  |  56.7  |  25.5  |  55.7  |  38.4  |  37.5  |  24.7  |  50.8  |  33.2  |  33.4  |  16.1  | 41.78 |\n",
    "| Paper |  43.5  |  77.0  |  94.8  |  88.5  |  54.5  |  41.0  |  32.3  |  46.5  |  45.7  |  37.0  |  42.6  |  29.3  |  52.7  |\n",
    "\n",
    "### 3. kennen-io\n",
    "The average accuracy are 36.78% and 38.66% which are both much lower than the accuracy in the paper. The model we implemented is overfitting with 91.1% training accuracy.\n",
    "\n",
    "|         |  act  |  drop  |  pool  |  ks    |  #conv |  #fc   |  #par  |  ens   |  alg   |  bs  |  size  |  split |  avg|\n",
    "|:------|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|\n",
    "| Impelment result 1 |  42.5  |  50.0  |  10.0  |  50.1  |  39.2  |  32.3  |  51.5  |  0.0   |  0.2   |  49.1  |  62.6  |  66.8 | 36.78 |\n",
    "| Impelment result 2 |  70.3  |  0.0  |  52.6  |  0.0  |  62.9  |  45.9  |  34.9  |  50.1  |  12.5  |  39.7  |  50.0  |  38.1  |  38.66  |\n",
    "| Paper |  88.4  |  95.8  |  99.5  |  97.7  |  80.3  |  80.2  |  45.2  |  60.2  |  79.3  |  54.3  |  84.8  |  95.6  |  80.1  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": " ProjectTemplateCS6316.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
